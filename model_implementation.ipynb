{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feather In Focus Kaggle Challenge\n",
    "\n",
    "Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    confusion_matrix, \n",
    "    classification_report,\n",
    "    accuracy_score\n",
    ")\n",
    "from transformers import (\n",
    "    ViTForImageClassification, \n",
    "    ViTImageProcessor, \n",
    "    AdamW, \n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path('aml-2024-feather-in-focus')\n",
    "class_names = np.load(base_dir / \"class_names.npy\", allow_pickle=True).item()\n",
    "train_df = pd.read_csv(base_dir / 'train_images.csv')\n",
    "test_df = pd.read_csv(base_dir / 'test_images_path.csv')\n",
    "attributes = np.load(base_dir / 'attributes.npy', allow_pickle=True)\n",
    "\n",
    "with open(base_dir / 'attributes.txt', 'r') as f:\n",
    "    attributes_names = f.read().splitlines()\n",
    "\n",
    "label_to_name = {v: k.split('.')[1] for k, v in class_names.items()}\n",
    "train_df['bird_name'] = train_df['label'].map(label_to_name)\n",
    "\n",
    "# class_distribution = train_df['label'].value_counts()\n",
    "plt.figure(figsize=(15, 6))\n",
    "ax = sns.countplot(data=train_df, y='bird_name')\n",
    "plt.title('Distribution of Bird Species in Training Set')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Species Name')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.histplot(data=train_df, x='label')\n",
    "plt.title('Distribution of Classes')\n",
    "plt.xlabel('Species Label')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of classes: {len(train_df[\"bird_name\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = train_df['image_path'].iloc[0].lstrip('/') \n",
    "sample_image_path = base_dir / 'train_images' / sample_path\n",
    "sample_image = tf.keras.preprocessing.image.load_img(sample_image_path)\n",
    "sample_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check image size and format\n",
    "image_sizes = []\n",
    "for path in train_df['image_path'][:100]:\n",
    "    clean_path = path.lstrip('/')\n",
    "    full_path = base_dir / 'train_images' / clean_path\n",
    "    img = tf.keras.preprocessing.image.load_img(full_path)\n",
    "    image_sizes.append(img.size)\n",
    "\n",
    "\n",
    "plt.hist(image_sizes)\n",
    "plt.xlabel('Image Size')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Image Sizes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and Dataset functions definition\n",
    "\n",
    "Note that this uses data augmentation with the `augment_multiplier` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, processor, augment=False, augment_multiplier=3):\n",
    "        \"\"\"\n",
    "        Custom dataset for bird images with gentle augmentation\n",
    "\n",
    "        Args:\n",
    "            image_paths (list): List of paths to bird images\n",
    "            labels (list): Corresponding labels for images\n",
    "            processor (ViTImageProcessor): Image processor for transformations\n",
    "            augment (bool): Whether to apply data augmentation\n",
    "        \"\"\"\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.processor = processor\n",
    "        self.augment_multiplier = augment_multiplier\n",
    "        self.augment = augment\n",
    "\n",
    "        # More conservative augmentation\n",
    "        self.augmentation = transforms.Compose([\n",
    "            transforms.RandomRotation(10),  # Small rotation, max 10 degrees\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.2,  # Small brightness variation\n",
    "                contrast=0.2,    # Small contrast variation\n",
    "                saturation=0.15,  # Small saturation variation\n",
    "                hue=0.05         # Very small hue shift\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.augment:\n",
    "            return len(self.image_paths) * self.augment_multiplier\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = idx\n",
    "        if self.augment:\n",
    "            # Calculate the original image index and augmentation variant\n",
    "            original_idx = idx % len(self.image_paths)\n",
    "            augment_variant = idx // len(self.image_paths)\n",
    "\n",
    "            image = Image.open(self.image_paths[original_idx]).convert('RGB')\n",
    "\n",
    "            # Apply different augmentations for each variant\n",
    "            if augment_variant > 0:\n",
    "                image = self.augmentation(image)\n",
    "        else:\n",
    "            image = Image.open(self.image_paths[original_idx]).convert('RGB')\n",
    "\n",
    "        # Process image using ViT image processor\n",
    "        inputs = self.processor(images=image, return_tensors='pt')\n",
    "        return {\n",
    "            'pixel_values': inputs['pixel_values'].squeeze(),\n",
    "            'labels': torch.tensor(self.labels[original_idx])\n",
    "        }\n",
    "\n",
    "def process_image_paths(df, base_path):\n",
    "    \"\"\"\n",
    "    Process image paths by adding a base path and normalizing Windows paths\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing image paths\n",
    "        base_path (str): Base directory path to prepend to image paths\n",
    "        path_column (str, optional): Name of the column containing image paths\n",
    "\n",
    "    Returns:\n",
    "        list: Full image paths with base path added and normalized\n",
    "    \"\"\"\n",
    "    # Normalize paths to work across different operating systems\n",
    "    def normalize_path(path):\n",
    "        # Replace Windows-style backslashes with forward slashes\n",
    "        normalized = path.replace('/', '\\\\')\n",
    "        # Remove leading slash if present to avoid double slashing\n",
    "        if normalized.startswith('\\\\'):\n",
    "            normalized = normalized[1:]\n",
    "            print(normalized)\n",
    "        return normalized\n",
    "\n",
    "\n",
    "    full_paths = []\n",
    "    for i, path in enumerate(df):\n",
    "        sample_path = train_df['image_path'].iloc[i].lstrip('/')\n",
    "        sample_image_path = base_dir / 'train_images' / sample_path\n",
    "        full_paths.append(sample_image_path)\n",
    "\n",
    "    # Combine base path with normalized image paths\n",
    "    # full_paths = [\n",
    "    #     os.path.normpath(os.path.join(base_path, normalize_path(path)))\n",
    "    #     for path in df\n",
    "    # ]\n",
    "\n",
    "    return full_paths\n",
    "\n",
    "def prepare_data(image_paths, labels):\n",
    "    \"\"\"\n",
    "    Prepare data when you already have image paths and labels\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): List of full paths to images\n",
    "        labels (list): Corresponding labels for images\n",
    "\n",
    "    Returns:\n",
    "        tuple: image_paths, labels, and a dictionary mapping labels to indices\n",
    "    \"\"\"\n",
    "    # Create a mapping of unique labels to integer indices\n",
    "    unique_labels = sorted(set(labels))\n",
    "    class_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "    image_paths = process_image_paths(image_paths, base_dir)\n",
    "    # image_paths = [path.replace('\\\\', '/') for path in image_paths]\n",
    "\n",
    "    # Convert string labels to integer indices\n",
    "    integer_labels = [class_to_idx[label] for label in labels]\n",
    "\n",
    "    return image_paths, integer_labels, class_to_idx\n",
    "\n",
    "def fine_tune_vit(num_epochs=5, batch_size=16, learning_rate=2e-5):\n",
    "    \"\"\"\n",
    "    Fine-tune Vision Transformer for bird classification\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Directory containing bird images\n",
    "        num_epochs (int): Number of training epochs\n",
    "        batch_size (int): Batch size for training\n",
    "        learning_rate (float): Learning rate for optimization\n",
    "    \"\"\"\n",
    "    # Load pre-trained model and processor\n",
    "    processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        'google/vit-base-patch16-224-in21k',\n",
    "        num_labels=len(train_df['bird_name'].unique()),\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    # Prepare data\n",
    "    image_paths, labels, class_to_idx = prepare_data(train_df['image_path'], train_df['bird_name'])\n",
    "\n",
    "    print(image_paths)\n",
    "    # Split into train and validation sets\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        image_paths, labels, test_size=0.2, random_state=42, stratify=train_df['bird_name']\n",
    "    )\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = BirdDataset(train_paths, train_labels, processor, augment=True, augment_multiplier=2)\n",
    "    val_dataset = BirdDataset(val_paths, val_labels, processor, augment=False)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Prepare optimizer and learning rate scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using {device}')\n",
    "    model.to(device)\n",
    "\n",
    "    metrics_epoch = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch in tqdm.tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = {k: v.to(device) for k, v in batch.items()\n",
    "                      if k != 'labels'}\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {k: v.to(device) for k, v in batch.items()\n",
    "                          if k != 'labels'}\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(**inputs, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                logits = outputs.logits\n",
    "                predictions = torch.argmax(logits, dim=1)\n",
    "                correct_predictions += (predictions == labels).sum().item()\n",
    "                total_predictions += labels.size(0)\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        metrics = {}\n",
    "        metrics['epoch'] = epoch\n",
    "        metrics['train_loss'] = avg_train_loss\n",
    "        metrics['val_loss'] = avg_val_loss\n",
    "        metrics['val_accuracy'] = val_accuracy\n",
    "\n",
    "        metrics_epoch.append(metrics)\n",
    "\n",
    "        # Save the fine-tuned model\n",
    "        model.save_pretrained(f'./bird_classification_model_{epoch}')\n",
    "        processor.save_pretrained(f'./bird_classification_model_{epoch}')\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_epoch)\n",
    "    metrics_df.to_csv('metrics.csv', index=False)\n",
    "\n",
    "    return model, processor, class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, proc, class_to_idx = fine_tune_vit(num_epochs=15, batch_size=32, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train set metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, device=None):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation function\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model\n",
    "        val_loader (torch.utils.data.DataLoader): Validation data loader\n",
    "        device (torch.device, optional): Device to run evaluation on\n",
    "    \n",
    "    Returns:\n",
    "        dict: Comprehensive evaluation metrics\n",
    "    \"\"\"\n",
    "    # Use GPU if available and not specified\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Prepare model for evaluation\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Lists to store predictions and true labels\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            # Move inputs and labels to device\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            # Get predictions\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            # Collect predictions and labels\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'f1_macro': f1_score(all_labels, all_preds, average='macro'),\n",
    "        'f1_micro': f1_score(all_labels, all_preds, average='micro'),\n",
    "        'f1_weighted': f1_score(all_labels, all_preds, average='weighted'),\n",
    "        'precision_macro': precision_score(all_labels, all_preds, average='macro'),\n",
    "        'precision_micro': precision_score(all_labels, all_preds, average='micro'),\n",
    "        'precision_weighted': precision_score(all_labels, all_preds, average='weighted'),\n",
    "        'recall_macro': recall_score(all_labels, all_preds, average='macro'),\n",
    "        'recall_micro': recall_score(all_labels, all_preds, average='micro'),\n",
    "        'recall_weighted': recall_score(all_labels, all_preds, average='weighted')\n",
    "    }\n",
    "    \n",
    "    return metrics, all_preds, all_labels\n",
    "\n",
    "def plot_confusion_matrix(all_labels, all_preds, class_names, normalize=True):\n",
    "    \"\"\"\n",
    "    Create and plot confusion matrix\n",
    "    \n",
    "    Args:\n",
    "        all_labels (list): True labels\n",
    "        all_preds (list): Predicted labels\n",
    "        class_names (list): List of class names\n",
    "        normalize (bool): Whether to normalize confusion matrix\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: Confusion matrix plot\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Normalize if requested\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', \n",
    "                xticklabels=class_names, \n",
    "                yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt.gcf()\n",
    "\n",
    "def generate_classification_report(all_labels, all_preds, class_names):\n",
    "    \"\"\"\n",
    "    Generate detailed classification report\n",
    "    \n",
    "    Args:\n",
    "        all_labels (list): True labels\n",
    "        all_preds (list): Predicted labels\n",
    "        class_names (list): List of class names\n",
    "    \n",
    "    Returns:\n",
    "        str: Detailed classification report\n",
    "    \"\"\"\n",
    "    return classification_report(\n",
    "        all_labels, \n",
    "        all_preds, \n",
    "        target_names=class_names,\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "# Example usage\n",
    "def main(model, processor, class_to_idx, val_dataset):\n",
    "    # Assume you have your model, validation loader, and class names\n",
    "    # model, processor, class_to_idx = load_model()\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "    \n",
    "    # Get class names (convert index to name)\n",
    "    class_names = [k for k, v in sorted(class_to_idx.items(), key=lambda item: item[1])]\n",
    "    \n",
    "    # Evaluate model\n",
    "    metrics, all_preds, all_labels = evaluate_model(model, val_loader)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"Model Evaluation Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm_fig = plot_confusion_matrix(all_labels, all_preds, class_names)\n",
    "    cm_fig.savefig('confusion_matrix.png')\n",
    "    \n",
    "    # Generate classification report\n",
    "    report_dict = generate_classification_report(all_labels, all_preds, class_names)\n",
    "    \n",
    "    return report_dict\n",
    "\n",
    "proc = ViTImageProcessor.from_pretrained('bird_classification_model_2')\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'bird_classification_model_2',\n",
    "    num_labels=len(train_df['bird_name'].unique()),\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# test_df['bird_name'] = test_df['label'].map(label_to_name)\n",
    "tot_paths, tot_labels, class_to_idx = prepare_data(train_df['image_path'], train_df['bird_name'])\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    tot_paths, tot_labels, test_size=0.2, random_state=42, stratify=train_df['bird_name']\n",
    ")\n",
    "val_dataset = BirdDataset(val_paths, val_labels, proc)\n",
    "report_dict = main(model, proc, class_to_idx, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = [report_dict[k]['f1-score'] for k in train_df['bird_name'].unique()]\n",
    "min_f1 = min(f1_scores)\n",
    "max_f1 = max(f1_scores)\n",
    "print(f\"Min F1 Score: {min_f1}\")\n",
    "print(f\"Max F1 Score: {max_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_with_min_f1 = [f for f in train_df['bird_name'].unique() if report_dict[f]['f1-score'] == min_f1]\n",
    "bird_with_max_f1 = [f for f in train_df['bird_name'].unique() if report_dict[f]['f1-score'] == max_f1]\n",
    "print(bird_with_min_f1)\n",
    "print(bird_with_max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size': 16}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "fig.patch.set_alpha(0)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.violinplot(f1_scores, positions=[0])\n",
    "ax.set_xlim(0, 0.30)\n",
    "ax.set_xlabel('Proportion of species')\n",
    "ax.set_ylabel('F1 Score')\n",
    "ax.set_title('F1 Score Distribution by Bird Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestBirdDataset(Dataset):\n",
    "    def __init__(self, image_paths, processor):\n",
    "        # Convert paths to strings if they're WindowsPath objects\n",
    "        self.image_paths = [str(path) for path in image_paths]\n",
    "        self.processor = processor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Open image and process\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        inputs = self.processor(images=image, return_tensors='pt')\n",
    "        \n",
    "        return {\n",
    "            'pixel_values': inputs['pixel_values'].squeeze(),\n",
    "            'image_path': image_path  # or filename if you prefer\n",
    "        }\n",
    "\n",
    "def predict_images(model, processor, image_paths, class_to_idx, batch_size=16):\n",
    "    \"\"\"\n",
    "    Predict labels for a set of images\n",
    "    \n",
    "    Args:\n",
    "        model (ViTForImageClassification): Trained model\n",
    "        processor (ViTImageProcessor): Image processor\n",
    "        image_paths (list): List of image file paths\n",
    "        class_to_idx (dict): Mapping of class indices to labels\n",
    "        batch_size (int, optional): Batch size for prediction\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping of image filenames to predicted labels\n",
    "    \"\"\"\n",
    "    # Prepare device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    test_dataset = TestBirdDataset(image_paths, processor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Prepare for predictions\n",
    "    predictions = {}\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            # Prepare inputs\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'image_path'}\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            # Map predictions to class names\n",
    "            batch_preds = preds.cpu().numpy()\n",
    "            batch_paths = batch['image_path']\n",
    "            \n",
    "            # Store predictions with filenames\n",
    "            for path, pred in zip(batch_paths, batch_preds):\n",
    "                filename = os.path.basename(path)\n",
    "                predictions[filename] = idx_to_class[pred]\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def test_prediction():\n",
    "    # Load model and processor\n",
    "    unique_labels = sorted(train_df['bird_name'].unique())\n",
    "    class_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    processor = ViTImageProcessor.from_pretrained('bird_classification_model_14')\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        'bird_classification_model_14',\n",
    "        num_labels=len(train_df['bird_name'].unique()),\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    \n",
    "    # Prepare image paths\n",
    "    image_paths, *_ = prepare_data(test_df['image_path'], train=False)\n",
    "\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = predict_images(model, processor, image_paths, class_to_idx)\n",
    "    \n",
    "    # Create DataFrame with predictions\n",
    "    results_df = pd.DataFrame.from_dict(predictions, orient='index', columns=['predicted_label'])\n",
    "    results_df.index.name = 'filename'\n",
    "    results_df.reset_index(inplace=True)\n",
    "    \n",
    "    return results_df, class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, class_to_idx = test_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_class_to_idx = train_df['bird_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_class_to_idx[66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['filename'] == '5.jpg']['predicted_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, label in enumerate(true_class_to_idx):\n",
    "    df['predicted_label'][df['predicted_label'] == label] = l + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all_pred to test_images_sample.csv\n",
    "pred_df = df.copy()\n",
    "pred_df['predicted_label'] = pred_df['predicted_label']\n",
    "pred_df = pred_df.rename(columns={'filename': 'id', 'predicted_label': 'label'})\n",
    "pred_df['id'] = np.linspace(1, 4000, 4000, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('test_images_sample5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
